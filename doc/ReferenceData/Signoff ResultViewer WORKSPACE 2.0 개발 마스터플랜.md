
## ğŸ“‹ ë¬¸ì„œ ì •ë³´

- **ëŒ€ìƒ**: AI ê¸°ë°˜ ìë™ ê°œë°œ ì‹œìŠ¤í…œ (Claude Code, Codex, Gemini CLI ë“±)
- **ëª©ì **: ì™„ì „í•œ êµ¬í˜„ ê°€ëŠ¥ ìˆ˜ì¤€ì˜ ê°œë°œ ëª…ì„¸ì„œ

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 ëª©ì ê³¼ ë¹„ì „

**WORKSPACE 2.0**ëŠ” ê¸°ì¡´ ResultViewerì˜ WORKSPACE 1.0ì„ ì™„ì „íˆ ëŒ€ì²´í•˜ëŠ” ì°¨ì„¸ëŒ€ í˜‘ì—… ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**í•µì‹¬ ëª©í‘œ:**

- ëŒ€ìš©ëŸ‰ Parquet ë°ì´í„°(10M-100M rows)ì˜ íš¨ìœ¨ì  ì²˜ë¦¬
- ë‹¤ì¤‘ ì‚¬ìš©ì ë™ì‹œ í¸ì§‘ì„ í†µí•œ íŒ€ í˜‘ì—… ê°•í™”
- Selective Loadingì„ í†µí•œ ë©”ëª¨ë¦¬ ìµœì í™”
- ë²„ì „ ê´€ë¦¬ë¥¼ í†µí•œ ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥

### 1.2 ê°œë°œ ë²”ìœ„

**Phase 1 (í˜„ì¬ ì½”ë“œ):**
- Read/Edit Mode & Full Lock

**ì‹ ê·œ ê³„íš (ê°œë°œ ê³„íš):**

- **í†µí•© Phase**: Selective Loading + Partial Lock + Merge Update + Version Managementë¥¼ í•˜ë‚˜ì˜ Phaseë¡œ ì™„ì„±
- Phase 1ì˜ file_mode.py (SegmentedControl ë°©ì‹) ëŒ€ì²´
- workspace_explorer.py (WORKSPACE 1.0) ì™„ì „ ì œê±°

### 1.3 ì£¼ìš” ê°œì„ ì‚¬í•­

#### ğŸ¯ ê¸°ì¡´ Phase 1 ëŒ€ë¹„ ì£¼ìš” ë³€ê²½ì 

| í•­ëª©      | Phase 1 (ê¸°ì¡´)     | WORKSPACE 2.0 (ì‹ ê·œ)           |
| ------- | ---------------- | ---------------------------- |
| ë°ì´í„° ë¡œë”©  | ì „ì²´ íŒŒì¼ ë¡œë“œ         | Selective Loading (í•„í„°ë§ëœ ë¶€ë¶„ë§Œ) |
| Lock ë°©ì‹ | Full Lockë§Œ ì§€ì›    | Full Lock + Partial Lock     |
| ë™ì‹œ í¸ì§‘   | 1ëª…ë§Œ í¸ì§‘ ê°€ëŠ¥        | ì—¬ëŸ¬ ëª… ë™ì‹œ í¸ì§‘ (ì˜ì—­ ë¶„ë¦¬)           |
| ì €ì¥ ë°©ì‹   | ì „ì²´ ë®ì–´ì“°ê¸°          | Merge Update (ìˆ˜ì • ë¶€ë¶„ë§Œ ë³‘í•©)     |
| ë²„ì „ ê´€ë¦¬   | ê°„ë‹¨í•œ ë°±ì—…           | .version íŒŒì¼ ê¸°ë°˜ ì²´ê³„ì  ê´€ë¦¬        |
| Mode ì „í™˜ | SegmentedControl | Selective Loading Dialog     |

### 1.4 ì‚¬ìš©ì í™˜ê²½

- **ëŒ€ìƒ ì‚¬ìš©ì**: ë©”ëª¨ë¦¬ ì„¤ê³„ ì—”ì§€ë‹ˆì–´ ì•½ 300ëª…
- **ì‹¤í–‰ í™˜ê²½**: LSF ê¸°ë°˜ HPC Linux ì‹œìŠ¤í…œ
- **ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡°**: FlaskWebGUIë¥¼ í†µí•œ ê°œë³„ ì‚¬ìš©ìë³„ Dash App ì¸ìŠ¤í„´ìŠ¤
- **ë°ì´í„° ì €ì¥ì†Œ**: NFS ë§ˆìš´íŠ¸ëœ ì¤‘ì•™ WORKSPACE (ê¶Œí•œ 777)
    - ê°œë°œ ì¤‘: `/home/deepwonwoo/resultviewer/WORKSPACE`
    - ë°°í¬ ì‹œ: NFS ìŠ¤í† ë¦¬ì§€ ê²½ë¡œë¡œ ë³€ê²½ (CONFIG.WORKSPACE)
- **ë°ì´í„° ê·œëª¨**: 10ë§Œ ~ 1ì–µ í–‰ì˜ Parquet DataFrame

ê° ì—”ì§€ë‹ˆì–´ë§ˆë‹¤ Linux HPC Systemì—ì„œ login nodeì—ì„œ lsfë¡œ resultviewer jobì„ ì œì¶œí•˜ì—¬ ê°ê°ì˜ ResultViewer Dash Appì„ ì‹¤í–‰. ê·¸ëŸ°ë° Workspaceì˜ ì¤‘ì•™ì €ì¥ì†Œì—ì„œ parquetí˜•ì‹ì˜ dataframe ë°ì´í„°ë¥¼ ì—´ê³  í¸ì§‘í• í…ë°, ì—¬ëŸ¬ëª…ì´ ê°™ì€íŒŒì¼ì„ ì‘ì—…í• ë•Œ ì‹¤ì‹œê°„ ë™ì‹œí¸ì§‘ì€ ì•„ë‹ˆë”ë¼ë„ ì¶©ëŒì—†ì´ í˜‘ì—…ì„ ì§€ì›í•˜ê¸°ìœ„í•´ WORKSPACE 2.0ì„ ê°œë°œ.
### 1.5 ê¸°ìˆ  ìŠ¤íƒ

**í”„ë ˆì„ì›Œí¬ & ë¼ì´ë¸ŒëŸ¬ë¦¬:**

- **Dash**: Plotly Dash ê¸°ë°˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
- **dash_ag_grid**: ë°ì´í„° ê·¸ë¦¬ë“œ (SSRM - Server-Side Row Model)
- **dash_mantine_components (dmc)**: ì£¼ìš” UI ì»´í¬ë„ŒíŠ¸
- **dash_blueprint_components (dbpc)**: ë³´ì¡° UI (Icon, Toast)
- **polars**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ (pandasë³´ë‹¤ 10-100ë°° ë¹ ë¦„)
- **dash-flexlayout**: ë ˆì´ì•„ì›ƒ ê´€ë¦¬

**ê°œë°œ & í…ŒìŠ¤íŠ¸:**

- **Playwright MCP**: E2E í…ŒìŠ¤íŠ¸ ìë™í™” (í•„ìˆ˜ ì‚¬ìš©)
- **pytest**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- **ë‹¤ì¤‘ Python ì¸ìŠ¤í„´ìŠ¤**: ë™ì‹œ ì ‘ì† ì‹œë®¬ë ˆì´ì…˜
(ê·¸ë°–ì˜ ë‹¤ì–‘í•œ ë°©ë²•)
---

## 2. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 2.1 ì „ì²´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ì‚¬ìš©ì ë ˆì´ì–´                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User 1 Dash App  â”‚  User 2 Dash App  â”‚  User N Dash App   â”‚
â”‚  (FlaskWebGUI)    â”‚  (FlaskWebGUI)    â”‚  (FlaskWebGUI)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   NFS WORKSPACE  â”‚
                    â”‚  (ì¤‘ì•™ ì €ì¥ì†Œ)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚ Parquet  â”‚      â”‚  Lock ì‹œìŠ¤í…œ    â”‚   â”‚   Version   â”‚
   â”‚  Files   â”‚      â”‚ Full + Partial â”‚   â”‚  Management â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°

ê°€ëŠ¥í•˜ë‹¤ë©´ resultviewer/components/menu/home/item/workspaceì—ì„œ workspace2.0ê´€ë ¨ ì½”ë“œ ê°œë°œ. 
```
resultviewer/
â”œâ”€â”€ app.py                          # Dash ì•± ì§„ì…ì 
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ RV.py                       # ResultViewer ë©”ì¸
â”‚   â”œâ”€â”€ grid/
â”‚   â”‚   â”œâ”€â”€ data_grid.py            # Dash AG Grid ë©”ì¸
â”‚   â”‚   â””â”€â”€ dag/
â”‚   â”‚       â”œâ”€â”€ server_side_operations.py
â”‚   â”‚       â””â”€â”€ column_definitions.py
â”‚   â””â”€â”€ menu/
â”‚       â””â”€â”€ home/
â”‚           â””â”€â”€ item/
â”‚               â”œâ”€â”€ open.py         # ë¡œì»¬ íŒŒì¼ ì—´ê¸°
â”‚               â”œâ”€â”€ save.py         # ì €ì¥
â”‚               â””â”€â”€ workspace/      # âœ¨ WORKSPACE 2.0
â”‚                   â”œâ”€â”€ layout.py              # ë©”ì¸ ë ˆì´ì•„ì›ƒ
â”‚                   â”œâ”€â”€ file_explorer.py       # íŒŒì¼ íƒìƒ‰ê¸°
â”‚                   â”œâ”€â”€ file_uploader.py       # íŒŒì¼ ì—…ë¡œë”
â”‚                   â”œâ”€â”€ folder_manager.py      # í´ë” ê´€ë¦¬
â”‚                   â”œâ”€â”€ metadata_editor.py     # ë©”íƒ€ë°ì´í„° í¸ì§‘
â”‚                   â”œâ”€â”€ selective_loader.py    # â­ Selective Loading UI
â”‚                   â”œâ”€â”€ version_viewer.py      # â­ ë²„ì „ ê´€ë¦¬ UI
â”‚                   â””â”€â”€ core/
â”‚                       â”œâ”€â”€ metadata_utils.py       # ë©”íƒ€ë°ì´í„° ìƒì„±
â”‚                       â”œâ”€â”€ file_utils.py           # íŒŒì¼ ì‹œìŠ¤í…œ
â”‚                       â”œâ”€â”€ lock_manager.py         # â­ Lock ê´€ë¦¬ (Full + Partial)
â”‚                       â”œâ”€â”€ storage_utils.py        # íŒŒì¼/í´ë” CRUD
â”‚                       â”œâ”€â”€ merge_updater.py        # â­ Merge Update
â”‚                       â””â”€â”€ version_manager.py      # â­ ë²„ì „ ê´€ë¦¬
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config.py                   # CONFIG.WORKSPACE
â”‚   â”œâ”€â”€ logging_utils.py            # logger, Toast
â”‚   â”œâ”€â”€ data_processing.py          # file2df, validate_df
â”‚   â””â”€â”€ db_management.py            # SSDF (Singleton DataFrame)
â””â”€â”€ tests/                          # E2E í…ŒìŠ¤íŠ¸ (Playwright)
```

**ë²”ë¡€:**

- âœ¨ ì‹ ê·œ ë˜ëŠ” ëŒ€í­ ìˆ˜ì •
- â­ í•µì‹¬ ì‹ ê·œ ê¸°ëŠ¥



### 2.3 WORKSPACE íŒŒì¼ ì‹œìŠ¤í…œ êµ¬ì¡°

#### í‘œì¤€ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
WORKSPACE/
â”œâ”€â”€ {PRODUCT}/                    # ì˜ˆ: D1b
â”‚   â””â”€â”€ {REVISION}/               # ì˜ˆ: R00
â”‚       â””â”€â”€ {BLOCK}/              # ì˜ˆ: FULLCHIP
â”‚           â””â”€â”€ {TOOL}/           # ì˜ˆ: DRIVER_KEEPER
â”‚               â”œâ”€â”€ result.parquet           # ì‹¤ì œ ë°ì´í„°
â”‚               â”œâ”€â”€ result.meta              # ë©”íƒ€ë°ì´í„°
â”‚               â”œâ”€â”€ result.lock              # Full Lock
â”‚               â”œâ”€â”€ result.{user1}_{timestamp}.lock  # Partial Lock
â”‚               â”œâ”€â”€ result.merge.lock        # Merge ì‘ì—… ì¤‘ ì„ì‹œ Lock
â”‚               â”œâ”€â”€ result.version           # ë²„ì „ ì •ë³´
â”‚               â””â”€â”€ backup/                 # ë²„ì „ ë°±ì—… í´ë”
â”‚                   â”œâ”€â”€ result_v1_20250105_090000.parquet
â”‚                   â”œâ”€â”€ result_v2_20250105_100000.parquet
â”‚                   â””â”€â”€ result_v3_20250105_110000.parquet
â””â”€â”€ USERS/                        # Personal Space
    â””â”€â”€ {username}/
        â””â”€â”€ temp_analysis.parquet
```

#### íŒŒì¼ëª… ê·œì¹™

- **ë°ì´í„° íŒŒì¼**: `{basename}.parquet`
- **ë©”íƒ€ë°ì´í„°**: `{basename}.meta`
- **Full Lock**: `{basename}.lock`
- **Partial Lock**: `{basename}.{user}_{timestamp}.lock`
- **Merge Lock**: `{basename}.merge.lock` (ì €ì¥ ì¤‘ ì„ì‹œ)
- **ë²„ì „ ì •ë³´**: `{basename}.version`
- **ë²„ì „ ë°±ì—…**: `backup/{basename}_v{N}_{timestamp}.parquet`

### 2.4 Lock íŒŒì¼ êµ¬ì¡°

#### Full Lock

```json
{
  "user": "deepwonwoo",
  "type": "full",
  "locked_at": "2025-01-08T12:30:00"
}
```

#### Partial Lock

```json
{
  "user": "deepwonwoo",
  "type": "partial",
  "locked_at": "2025-01-08T12:30:00",
  "filter_expr": "col('Part').eq('CPU') & col('waiver').eq('Result')",
  "selected_columns": ["uniqid", "waiver", "Part", "Net", "user", "waiver_comment"],
  "locked_uniqids": [1, 2, 3, ..., 100]  # ì „ì²´ uniqid ë¦¬ìŠ¤íŠ¸ í¬í•¨
}
```

**ì¤‘ìš” ì„¤ê³„ ê²°ì •:**

- âŒ ë³„ë„ `.lock_uniqids_{hash}.json` íŒŒì¼ ë¶ˆí•„ìš”
- âœ… Lock íŒŒì¼ ì•ˆì— ëª¨ë“  ì •ë³´ í¬í•¨ (ë‹¨ì¼ íŒŒì¼ ê´€ë¦¬)
- âœ… uniqid ë¦¬ìŠ¤íŠ¸ ì „ì²´ ì €ì¥ (hash ë°©ì‹ X)

### 2.5 ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ

`.meta` íŒŒì¼ (JSON):

```json
{
  "start_date": "2025-01-05",
  "end_date": "2025-06-30",
  "assignee": "",
  "visible": "False",
  "sol_dir": "/path/to/signoff/launcher",
  "waive": {
    "result": 1000,
    "waiver": 50,
    "fixed": 30,
    "task_progress": 0.074,
    "details": [
      {
        "Block": "FULLCHIP",
        "Part": "CPU",
        "Result": 500,
        "Waiver": 30,
        "Fixed": 20,
        "Progress": 0.09
      }
    ],
    "warn_users": "user1,user2"
  },
  "last_modified": "2025-01-08T04:33:38.123456",
  "modified_by": "deepwonwoo",
  "uploaded_at": "2025-01-05T09:00:00.000000",
  "uploaded_by": "deepwonwoo",
  "filterModel": {}
}
```

### 2.6 ë²„ì „ ì •ë³´ ìŠ¤í‚¤ë§ˆ

`.version` íŒŒì¼ (JSON):

```json
{
  "current_version": 5,
  "history": [
    {
      "version": 1,
      "backup_file": "result_v1_20250105_090000.parquet",
      "created_by": "user1",
      "created_at": "2025-01-05T09:00:00",
      "action": "full_save",
      "filter_expr": null,
    },
    {
      "version": 2,
      "backup_file": "result_v2_20250105_100000.parquet",
      "created_by": "user2",
      "created_at": "2025-01-05T10:00:00",
      "action": "partial_save",
      "filter_expr": "col('Part').eq('CPU')",
    }
  ]
}
```

---

## 3. Selective Loading ìƒì„¸ ëª…ì„¸

### 3.1 ì‚¬ìš©ì ì›Œí¬í”Œë¡œìš°

```
1. ResultViewer ì‹¤í–‰ â†’ Home ë©”ë‰´ â†’ Open from Workspace
2. WORKSPACE Explorer ì—´ë¦¼ â†’ íŒŒì¼ íƒìƒ‰
3. íŒŒì¼ í´ë¦­ â†’ Selective Loading Dialog ìë™ í‘œì‹œ
4. [Dialog Stage 1] íŒŒì¼ ì •ë³´, Lock ìƒíƒœ, ìƒ˜í”Œ ë°ì´í„° ìë™ ë¡œë”©
5. ì‚¬ìš©ì ì„¤ì •:
   - ì»¬ëŸ¼ ì„ íƒ (ê¸°ë³¸: ì „ì²´ ì„ íƒ, ì‹œìŠ¤í…œ ì»¬ëŸ¼ì€ í•„ìˆ˜)
   - í•„í„° ì¡°ê±´ ì…ë ¥ (optional, Polars expression)
   - Lock ëª¨ë“œ ì„ íƒ (Read-Only / Partial Lock / Full Lock)
6. ì‹¤ì‹œê°„ ì˜ˆìƒ ì •ë³´ í‘œì‹œ:
   - ì˜ˆìƒ í–‰ ìˆ˜
   - ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
   - Lock ì¶©ëŒ ì—¬ë¶€
7. "Load Data" ë²„íŠ¼ í´ë¦­
8. ì¶©ëŒ ê²€ì‚¬ ìˆ˜í–‰
9. Lock íšë“ (Edit Modeì¸ ê²½ìš°)
10. ResultViewer Gridì— ë°ì´í„° ë¡œë”©
11. í¸ì§‘ ì‘ì—… ìˆ˜í–‰
12. ì €ì¥ ì‹œ Merge Update ì‹¤í–‰
```

### 3.2 UI êµ¬ì¡° (dmc ê¸°ë°˜)

#### Selective Loading Dialog

**ì»´í¬ë„ŒíŠ¸ ê³„ì¸µ:**

```python
dmc.Modal(
    id="selective-load-modal",
    size="xl",
    title="Selective Data Loading",
    children=[
        dmc.Stack([
            # â”â”â” Section 1: File Information â”â”â”
            dmc.Paper([
                dmc.Title("File Information", order=5),
                dmc.Grid([
                    dmc.Col(dmc.Text(f"Path: {display_path}"), span=12),
                    dmc.Col(dmc.Text(f"Size: {file_size}"), span=4),
                    dmc.Col(dmc.Text(f"Rows: {total_rows:,}"), span=4),
                    dmc.Col(dmc.Text(f"Columns: {total_cols}"), span=4),
                ]),
                dmc.Group([
                    # Lock ìƒíƒœ Badge
                    dmc.Badge(
                        "ğŸ”’ 2 users editing (user1, user2)",
                        color="orange"
                    ) if has_locks else dmc.Badge(
                        "âœ… Available",
                        color="green"
                    ),
                ]),
            ], withBorder=True, p="md", mb="md"),
            
            # â”â”â” Section 2: Sample Data (Optional, Accordion) â”â”â”
            dmc.Accordion([
                dmc.AccordionItem(
                    value="preview",
                    children=[
                        dmc.AccordionControl("ğŸ“Š Preview Data (10 rows)"),
                        dmc.AccordionPanel(
                            dmc.Table(...)  # ìƒ˜í”Œ 10í–‰
                        ),
                    ],
                ),
            ], mb="md"),
            
            # â”â”â” Section 3: Column Selection â”â”â”
            dmc.Stack([
                dmc.Title("Select Columns", order=5),
                dmc.Text("System columns (uniqid, waiver, user, waiver_comment) are always included.", size="sm", color="dimmed"),
                dmc.Group([
                    dmc.Button("Select All", id="select-all-cols", size="xs"),
                    dmc.Button("Deselect All", id="deselect-all-cols", size="xs"),
                ]),
                dmc.CheckboxGroup(
                    id="column-selection",
                    value=all_columns,  # ê¸°ë³¸: ì „ì²´ ì„ íƒ
                    children=[
                        dmc.Checkbox(
                            label=f"{col} ({dtype})",
                            value=col,
                            disabled=(col in system_cols)
                        )
                        for col, dtype in columns
                    ],
                ),
            ], mb="md"),
            
            # â”â”â” Section 4: Row Filter â”â”â”
            dmc.Stack([
                dmc.Title("Filter Rows (Optional)", order=5),
                dmc.Textarea(
                    id="filter-expression",
                    placeholder='ì˜ˆ: col("Part").eq("CPU") & col("waiver").eq("Result")',
                    minRows=3,
                    description="Polars expression syntax",
                ),
                dmc.Group([
                    dmc.Text("Suggested filters:", size="sm", color="dimmed"),
                    dmc.Button(
                        "My rows",
                        id="filter-my-rows",
                        size="xs",
                        variant="light",
                    ),
                    dmc.Button(
                        "Result rows",
                        id="filter-result-rows",
                        size="xs",
                        variant="light",
                    ),
                ]),
                # ì‹¤ì‹œê°„ ì˜ˆìƒ ì •ë³´
                dmc.Alert(
                    id="filter-preview-alert",
                    title="Preview",
                    color="blue",
                    children="",  # ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                ),
            ], mb="md"),
            
            # â”â”â” Section 5: Lock Mode Selection â”â”â”
            dmc.Stack([
                dmc.Title("Loading Mode", order=5),
                dmc.RadioGroup(
                    id="lock-mode-selection",
                    value="read",
                    children=[
                        dmc.Radio(
                            label="ğŸ“– Read-Only (View Only, No Lock)",
                            value="read",
                            description="ì—´ëŒ ì „ìš©, WORKSPACE ì €ì¥ ë¶ˆê°€",
                        ),
                        dmc.Radio(
                            label="ğŸ”“ Partial Lock (Edit Selected Rows)",
                            value="partial",
                            description="í•„í„°ë§ëœ ì˜ì—­ë§Œ í¸ì§‘ ê°€ëŠ¥, ë‹¤ë¥¸ ì‚¬ìš©ìì™€ ë™ì‹œ ì‘ì—… ê°€ëŠ¥",
                        ),
                        dmc.Radio(
                            label="ğŸ”’ Full Lock (Edit Entire File)",
                            value="full",
                            description="ì „ì²´ íŒŒì¼ ë…ì  í¸ì§‘, ë‹¤ë¥¸ ì‚¬ìš©ìëŠ” Read-Only",
                        ),
                    ],
                ),
            ], mb="md"),
            
            # â”â”â” Section 6: Action Buttons â”â”â”
            dmc.Group([
                dmc.Button(
                    "Load Data",
                    id="load-data-button",
                    color="blue",
                    size="md",
                    leftIcon=DashIconify(icon="mdi:check"),
                ),
                dmc.Button(
                    "Cancel",
                    id="cancel-load-button",
                    variant="outline",
                    size="md",
                ),
            ], position="right"),
            
        ], spacing="md"),
    ],
)
```

### 3.3 Callbacks ëª…ì„¸

#### 3.3.1 Dialog ì—´ê¸°

```python
@app.callback(
    Output("selective-load-modal", "opened"),
    Output("file-info-section", "children"),
    Output("column-selection", "children"),
    Output("filter-expression", "value"),
    Input("file-explorer-table", "cellClicked"),
    State("current-directory", "data"),
    prevent_initial_call=True,
)
def open_selective_loader(cell_clicked, current_dir):
    """
    File Explorerì—ì„œ íŒŒì¼ í´ë¦­ ì‹œ Dialog ì—´ê¸°
    
    ë¡œì§:
    1. íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
    2. pl.scan_parquet()ë¡œ ë©”íƒ€ì •ë³´ ì½ê¸° (ì´ í–‰ ìˆ˜, ì»¬ëŸ¼ ëª©ë¡)
    3. Lock ìƒíƒœ ìŠ¤ìº” (scan_all_locks())
    4. ìƒ˜í”Œ ë°ì´í„° 10í–‰ ì½ê¸° (head(10))
    5. UI ë Œë”ë§
    """
    if not cell_clicked:
        return no_update, no_update, no_update, no_update
    
    file_path = get_clicked_file_path(cell_clicked, current_dir)
    
    # Polars lazy evaluation
    lazy_df = pl.scan_parquet(file_path)
    schema = lazy_df.schema
    total_rows = lazy_df.select(pl.count()).collect().item()
    
    # Lock ìƒíƒœ
    locks = scan_all_locks(file_path)
    lock_badge = generate_lock_badge(locks)
    
    # ìƒ˜í”Œ ë°ì´í„°
    sample_df = lazy_df.head(10).collect()
    
    # UI ìƒì„±
    file_info = create_file_info_section(file_path, total_rows, schema, lock_badge)
    column_checkboxes = create_column_checkboxes(schema)
    
    return True, file_info, column_checkboxes, ""
```

#### 3.3.2 ì‹¤ì‹œê°„ í•„í„° ë¯¸ë¦¬ë³´ê¸°

```python
@app.callback(
    Output("filter-preview-alert", "children"),
    Output("load-data-button", "disabled"),
    Input("filter-expression", "value"),
    Input("column-selection", "value"),
    Input("lock-mode-selection", "value"),
    State("current-file-path", "data"),
    prevent_initial_call=True,
)
def update_filter_preview(filter_expr, selected_cols, lock_mode, file_path):
    """
    í•„í„° ì¡°ê±´ ë³€ê²½ ì‹œ ì˜ˆìƒ ì •ë³´ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
    
    ë¡œì§:
    1. í•„í„° ì¡°ê±´ íŒŒì‹± ë° ê²€ì¦
    2. pl.scan_parquet().filter(expr).select(pl.count())ë¡œ í–‰ ìˆ˜ ê³„ì‚°
    3. ë©”ëª¨ë¦¬ ì˜ˆì¸¡: (row_count Ã— col_count Ã— 8) / (1024^3) GB
    4. Lock ì¶©ëŒ ê²€ì‚¬ (lock_modeê°€ "partial" ë˜ëŠ” "full"ì¸ ê²½ìš°)
    5. ê²°ê³¼ í…ìŠ¤íŠ¸ ìƒì„±
    """
    if not filter_expr:
        # í•„í„° ì—†ìŒ
        lazy_df = pl.scan_parquet(file_path)
        filtered_rows = lazy_df.select(pl.count()).collect().item()
    else:
        try:
            # í•„í„° ì ìš©
            lazy_df = pl.scan_parquet(file_path).filter(eval(filter_expr))
            filtered_rows = lazy_df.select(pl.count()).collect().item()
        except Exception as e:
            return f"âŒ í•„í„° ë¬¸ë²• ì˜¤ë¥˜: {str(e)}", True
    
    # ë©”ëª¨ë¦¬ ì˜ˆì¸¡
    estimated_memory = (filtered_rows * len(selected_cols) * 8) / (1024**3)
    
    # Lock ì¶©ëŒ ê²€ì‚¬
    if lock_mode in ["partial", "full"]:
        can_acquire, conflict_msg = check_lock_availability(
            file_path, lock_mode, filter_expr, filtered_rows
        )
        if not can_acquire:
            return f"âš ï¸ {conflict_msg}", True
    
    preview_text = f"âœ… ì˜ˆìƒ: {filtered_rows:,} rows Ã— {len(selected_cols)} cols â‰ˆ {estimated_memory:.2f} GB"
    
    return preview_text, False
```

#### 3.3.3 Suggested Filters

```python
@app.callback(
    Output("filter-expression", "value", allow_duplicate=True),
    Input("filter-my-rows", "n_clicks"),
    Input("filter-result-rows", "n_clicks"),
    prevent_initial_call=True,
)
def apply_suggested_filter(my_clicks, result_clicks):
    """
    Suggested filter ë²„íŠ¼ í´ë¦­ ì‹œ ìë™ ì…ë ¥
    """
    ctx_id = ctx.triggered_id
    
    if ctx_id == "filter-my-rows":
        return f'col("user").eq("{CONFIG.USERNAME}")'
    elif ctx_id == "filter-result-rows":
        return 'col("waiver").eq("Result")'
    
    return no_update
```

#### 3.3.4 Load Data

```python
@app.callback(
    Output("selective-load-modal", "opened", allow_duplicate=True),
    Output("aggrid-overlay", "visible"),  # ë¡œë”© í‘œì‹œ
    Output("data-grid", "rowData"),
    Output("toaster", "children", allow_duplicate=True),
    Input("load-data-button", "n_clicks"),
    State("filter-expression", "value"),
    State("column-selection", "value"),
    State("lock-mode-selection", "value"),
    State("current-file-path", "data"),
    prevent_initial_call=True,
)
def load_data_with_selective_loading(n_clicks, filter_expr, selected_cols, lock_mode, file_path):
    """
    Load Data ë²„íŠ¼ í´ë¦­ ì‹œ ë°ì´í„° ë¡œë”©
    
    ë¡œì§:
    1. í˜„ì¬ ResultViewerê°€ Edit Modeì¸ì§€ í™•ì¸
       â†’ Edit Modeë¼ë©´ "ë¨¼ì € ì €ì¥í•˜ê±°ë‚˜ Read Modeë¡œ ì „í™˜í•˜ì„¸ìš”" ê²½ê³ 
    2. ë™ì¼ ì‚¬ìš©ìì˜ ê¸°ì¡´ Lock í™•ì¸
       â†’ ìˆë‹¤ë©´ ìë™ í•´ì œ (Aì•ˆ)
    3. Lock ì¶©ëŒ ê²€ì‚¬ (ìµœì¢… í™•ì¸)
    4. Lock íšë“ (lock_modeê°€ "partial" ë˜ëŠ” "full"ì¸ ê²½ìš°)
    5. ë°ì´í„° ë¡œë”©:
       - pl.scan_parquet().filter(expr).select(cols).collect()
    6. SSDFì— ì €ì¥:
       - SSDF.dataframe = df
       - SSDF.file_path = file_path
       - SSDF.readonly = (lock_mode == "read")
    7. AG Gridì— ë Œë”ë§
    8. Dialog ë‹«ê¸°
    """
    if not n_clicks:
        return no_update, no_update, no_update, no_update
    
    # Step 1: í˜„ì¬ Edit Mode ì²´í¬
    if SSDF.get_current_mode() == "edit":
        toast = dbpc.Toast(
            message="í˜„ì¬ ë‹¤ë¥¸ íŒŒì¼ì„ í¸ì§‘ ì¤‘ì…ë‹ˆë‹¤. ë¨¼ì € ì €ì¥í•˜ê±°ë‚˜ Read Modeë¡œ ì „í™˜í•˜ì„¸ìš”.",
            intent="warning",
            icon="warning-sign",
        )
        return no_update, no_update, no_update, [toast]
    
    # Step 2: ë™ì¼ ì‚¬ìš©ì ê¸°ì¡´ Lock ìë™ í•´ì œ
    release_existing_user_locks(file_path, CONFIG.USERNAME)
    
    # Step 3: Lock ì¶©ëŒ ê²€ì‚¬ (ìµœì¢…)
    if lock_mode in ["partial", "full"]:
        can_acquire, conflict_msg = perform_lock_conflict_check(
            file_path, lock_mode, filter_expr
        )
        if not can_acquire:
            toast = dbpc.Toast(
                message=conflict_msg,
                intent="danger",
                icon="error",
            )
            return no_update, False, no_update, [toast]
    
    # Step 4: ë¡œë”© í‘œì‹œ ì‹œì‘
    # (aggrid-overlay visible)
    
    try:
        # Step 5: Lock íšë“
        if lock_mode == "full":
            success = acquire_full_lock(file_path, CONFIG.USERNAME)
        elif lock_mode == "partial":
            success = acquire_partial_lock(
                file_path, CONFIG.USERNAME, filter_expr, selected_cols
            )
        else:
            success = True  # Read-OnlyëŠ” Lock ë¶ˆí•„ìš”
        
        if not success:
            raise Exception("Lock íšë“ ì‹¤íŒ¨")
        
        # Step 6: ë°ì´í„° ë¡œë”©
        lazy_df = pl.scan_parquet(file_path)
        
        if filter_expr:
            lazy_df = lazy_df.filter(eval(filter_expr))
        
        df = lazy_df.select(selected_cols).collect()
        
        # Step 7: SSDF ì €ì¥
        SSDF.dataframe = df
        SSDF.file_path = file_path
        SSDF.readonly = (lock_mode == "read")
        
        # Step 8: AG Grid ë Œë”ë§
        row_data = df.to_dicts()
        
        toast = dbpc.Toast(
            message=f"ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df):,} rows",
            intent="success",
            icon="tick",
        )
        
        return False, False, row_data, [toast]
        
    except Exception as e:
        logger.error(f"Data loading failed: {e}")
        toast = dbpc.Toast(
            message=f"ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}",
            intent="danger",
            icon="error",
        )
        return no_update, False, no_update, [toast]
```

---

## 4. Lock ì‹œìŠ¤í…œ ìƒì„¸ ëª…ì„¸

### 4.1 Lock ì¶©ëŒ ê²€ì‚¬ ì•Œê³ ë¦¬ì¦˜

```python
def check_lock_conflict(file_path: str, mode: str, filter_expr: str = None) -> Tuple[bool, str]:
    """
    Lock ì¶©ëŒ ê²€ì‚¬ í†µí•© ì•Œê³ ë¦¬ì¦˜
    
    Args:
        file_path: ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ
        mode: "read" | "partial" | "full"
        filter_expr: Partial Lockì¸ ê²½ìš° í•„í„° ì¡°ê±´
    
    Returns:
        (can_proceed: bool, message: str)
    
    ì•Œê³ ë¦¬ì¦˜:
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    1. ëª¨ë“  Lock íŒŒì¼ ìŠ¤ìº”
       - result.lock (Full Lock)
       - result.*.lock (Partial Locks)
    
    2. Full Lock ì¡´ì¬ í™•ì¸
       - ìˆê³ , ì†Œìœ ìê°€ ë‚˜ â†’ OK (ì¬íšë“)
       - ìˆê³ , ì†Œìœ ìê°€ ë‹¤ë¥¸ ì‚¬ëŒ â†’ FAIL
    
    3. ìš”ì²­ ëª¨ë“œê°€ Full Lockì¸ ê²½ìš°
       - ë‹¤ë¥¸ Lock(Full or Partial) ì¡´ì¬ â†’ FAIL
       - ì—†ìŒ â†’ OK
    
    4. ìš”ì²­ ëª¨ë“œê°€ Partial Lockì¸ ê²½ìš°
       - Full Lock ì¡´ì¬ â†’ FAIL
       - Partial Lockë“¤ê³¼ uniqid êµì§‘í•© í™•ì¸
         - êµì§‘í•© ìˆìŒ â†’ FAIL
         - êµì§‘í•© ì—†ìŒ â†’ OK
    
    5. ìš”ì²­ ëª¨ë“œê°€ Read-Onlyì¸ ê²½ìš°
       - í•­ìƒ OK (Lock ë¶ˆí•„ìš”)
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    """
    # Step 1: Lock íŒŒì¼ ìŠ¤ìº”
    lock_files = scan_all_locks(file_path)
    # ë°˜í™˜ ì˜ˆ: [
    #   {"type": "full", "user": "user1", "file": "result.lock"},
    #   {"type": "partial", "user": "user2", "file": "result.user2_20250108.lock", "uniqids": [...]}
    # ]
    
    # Step 2: Full Lock í™•ì¸
    full_lock = next((lock for lock in lock_files if lock["type"] == "full"), None)
    
    if full_lock:
        if full_lock["user"] == CONFIG.USERNAME:
            return True, ""  # ë‚´ê°€ ì´ë¯¸ Full Lock ë³´ìœ 
        else:
            return False, f"íŒŒì¼ì´ {full_lock['user']}ì— ì˜í•´ ì™„ì „íˆ ì ê²¨ìˆìŠµë‹ˆë‹¤."
    
    # Step 3: ìš”ì²­ ëª¨ë“œê°€ Full Lock
    if mode == "full":
        if len(lock_files) > 0:
            users = [lock["user"] for lock in lock_files]
            return False, f"ë‹¤ë¥¸ ì‚¬ìš©ìê°€ í¸ì§‘ ì¤‘ì…ë‹ˆë‹¤: {', '.join(users)}"
        else:
            return True, ""
    
    # Step 4: ìš”ì²­ ëª¨ë“œê°€ Partial Lock
    if mode == "partial":
        # uniqid ê³„ì‚° (í•„í„° ì¡°ê±´ ê¸°ë°˜)
        my_uniqids = calculate_uniqids_from_filter(file_path, filter_expr)
        my_uniqids_set = set(my_uniqids)
        
        # ê¸°ì¡´ Partial Lockë“¤ê³¼ êµì§‘í•© í™•ì¸
        for lock in lock_files:
            if lock["type"] == "partial":
                if lock["user"] == CONFIG.USERNAME:
                    continue  # ë‚´ Lockì€ ìŠ¤í‚µ
                
                locked_uniqids_set = set(lock["uniqids"])
                overlap = my_uniqids_set & locked_uniqids_set
                
                if len(overlap) > 0:
                    return False, f"ì¶©ëŒ: {lock['user']}ê°€ {len(overlap)}ê°œ í–‰ì„ í¸ì§‘ ì¤‘ì…ë‹ˆë‹¤."
        
        return True, ""
    
    # Step 5: Read-Only
    if mode == "read":
        return True, ""
    
    return False, "ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ"
```

### 4.2 Lock íŒŒì¼ ìŠ¤ìº”

```python
def scan_all_locks(file_path: str) -> List[dict]:
    """
    íŒŒì¼ì— ëŒ€í•œ ëª¨ë“  Lock ìŠ¤ìº”
    
    Returns:
        List[dict]: Lock ì •ë³´ ë¦¬ìŠ¤íŠ¸
        [
            {
                "type": "full",
                "user": "user1",
                "file": "result.lock",
                "locked_at": "2025-01-08T12:30:00"
            },
            {
                "type": "partial",
                "user": "user2",
                "file": "result.user2_20250108123000.lock",
                "locked_at": "2025-01-08T12:30:00",
                "filter_expr": "col('Part').eq('CPU')",
                "uniqids": [1, 2, 3, ...]
            }
        ]
    """
    actual_path = convert_to_actual_path(file_path)
    basename = os.path.splitext(os.path.basename(actual_path))[0]
    directory = os.path.dirname(actual_path)
    
    locks = []
    
    # Full Lock í™•ì¸
    full_lock_path = os.path.join(directory, f"{basename}.lock")
    if os.path.exists(full_lock_path):
        try:
            with open(full_lock_path, 'r') as f:
                lock_data = json.load(f)
            lock_data["file"] = full_lock_path
            locks.append(lock_data)
        except Exception as e:
            logger.warning(f"ì†ìƒëœ Lock íŒŒì¼: {full_lock_path}, {e}")
    
    # Partial Lockë“¤ ìŠ¤ìº”
    for file in os.listdir(directory):
        if file.startswith(f"{basename}.") and file.endswith(".lock") and file != f"{basename}.lock":
            lock_path = os.path.join(directory, file)
            try:
                with open(lock_path, 'r') as f:
                    lock_data = json.load(f)
                lock_data["file"] = lock_path
                locks.append(lock_data)
            except Exception as e:
                logger.warning(f"ì†ìƒëœ Lock íŒŒì¼: {lock_path}, {e}")
    
    return locks
```

### 4.3 uniqid ê³„ì‚°

```python
def calculate_uniqids_from_filter(file_path: str, filter_expr: str) -> List[int]:
    """
    í•„í„° ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” uniqid ë¦¬ìŠ¤íŠ¸ ê³„ì‚°
    
    ì£¼ì˜: ëŒ€ìš©ëŸ‰ íŒŒì¼ì˜ ê²½ìš° ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ
          â†’ í˜¸ì¶œí•˜ëŠ” ê³³ì—ì„œ aggrid-overlay í‘œì‹œ í•„ìˆ˜
    
    Args:
        file_path: Parquet íŒŒì¼ ê²½ë¡œ
        filter_expr: Polars í•„í„° í‘œí˜„ì‹ (ë¬¸ìì—´)
    
    Returns:
        List[int]: uniqid ë¦¬ìŠ¤íŠ¸
    """
    actual_path = convert_to_actual_path(file_path)
    
    if not filter_expr:
        # í•„í„° ì—†ìŒ â†’ ì „ì²´ uniqid
        df = pl.read_parquet(actual_path, columns=["uniqid"])
        return df["uniqid"].to_list()
    
    try:
        # Polars lazy evaluation
        uniqids = pl.scan_parquet(actual_path) \
                    .filter(eval(filter_expr)) \
                    .select("uniqid") \
                    .collect()["uniqid"].to_list()
        
        return uniqids
    except Exception as e:
        logger.error(f"uniqid ê³„ì‚° ì‹¤íŒ¨: {e}")
        raise
```

### 4.4 Lock íšë“

#### Full Lock

```python
def acquire_full_lock(file_path: str, user: str) -> bool:
    """
    Full Lock íšë“
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    actual_path = convert_to_actual_path(file_path)
    basename = os.path.splitext(os.path.basename(actual_path))[0]
    directory = os.path.dirname(actual_path)
    lock_path = os.path.join(directory, f"{basename}.lock")
    
    # Lock íŒŒì¼ ìƒì„±
    lock_data = {
        "user": user,
        "type": "full",
        "locked_at": datetime.now().isoformat(),
    }
    
    try:
        with open(lock_path, 'w') as f:
            json.dump(lock_data, f, indent=2)
        
        os.chmod(lock_path, 0o777)
        
        # NFS sync
        time.sleep(1)
        
        # ìƒì„± í™•ì¸
        if os.path.exists(lock_path):
            logger.info(f"Full Lock íšë“: {lock_path}")
            return True
        else:
            logger.error(f"Full Lock ìƒì„± ì‹¤íŒ¨: {lock_path}")
            return False
    
    except Exception as e:
        logger.error(f"Full Lock ìƒì„± ì˜¤ë¥˜: {e}")
        return False
```

#### Partial Lock

```python
def acquire_partial_lock(file_path: str, user: str, filter_expr: str, selected_columns: List[str]) -> bool:
    """
    Partial Lock íšë“
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    actual_path = convert_to_actual_path(file_path)
    basename = os.path.splitext(os.path.basename(actual_path))[0]
    directory = os.path.dirname(actual_path)
    
    # uniqid ê³„ì‚° (ì‹œê°„ ì†Œìš” ê°€ëŠ¥)
    locked_uniqids = calculate_uniqids_from_filter(file_path, filter_expr)
    
    # Lock íŒŒì¼ëª… ìƒì„±: result.{user}_{timestamp}.lock
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    lock_filename = f"{basename}.{user}_{timestamp}.lock"
    lock_path = os.path.join(directory, lock_filename)
    
    # Lock ë°ì´í„°
    lock_data = {
        "user": user,
        "type": "partial",
        "locked_at": datetime.now().isoformat(),
        "filter_expr": filter_expr,
        "selected_columns": selected_columns,
        "locked_uniqids": locked_uniqids,  # ì „ì²´ ë¦¬ìŠ¤íŠ¸ í¬í•¨
    }
    
    try:
        with open(lock_path, 'w') as f:
            json.dump(lock_data, f, indent=2)
        
        os.chmod(lock_path, 0o777)
        
        # NFS sync
        time.sleep(1)
        
        # ìƒì„± í™•ì¸
        if os.path.exists(lock_path):
            logger.info(f"Partial Lock íšë“: {lock_path}, {len(locked_uniqids)} uniqids")
            return True
        else:
            logger.error(f"Partial Lock ìƒì„± ì‹¤íŒ¨: {lock_path}")
            return False
    
    except Exception as e:
        logger.error(f"Partial Lock ìƒì„± ì˜¤ë¥˜: {e}")
        return False
```

### 4.5 Lock í•´ì œ

```python
def release_lock(file_path: str, user: str) -> bool:
    """
    ì‚¬ìš©ìì˜ Lock í•´ì œ (Full ë˜ëŠ” Partial)
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    actual_path = convert_to_actual_path(file_path)
    basename = os.path.splitext(os.path.basename(actual_path))[0]
    directory = os.path.dirname(actual_path)
    
    released = False
    
    # Full Lock í™•ì¸ ë° í•´ì œ
    full_lock_path = os.path.join(directory, f"{basename}.lock")
    if os.path.exists(full_lock_path):
        try:
            with open(full_lock_path, 'r') as f:
                lock_data = json.load(f)
            
            if lock_data.get("user") == user:
                os.remove(full_lock_path)
                logger.info(f"Full Lock í•´ì œ: {full_lock_path}")
                released = True
        except Exception as e:
            logger.error(f"Full Lock í•´ì œ ì‹¤íŒ¨: {e}")
    
    # Partial Lock í™•ì¸ ë° í•´ì œ
    for file in os.listdir(directory):
        if file.startswith(f"{basename}.{user}_") and file.endswith(".lock"):
            lock_path = os.path.join(directory, file)
            try:
                os.remove(lock_path)
                logger.info(f"Partial Lock í•´ì œ: {lock_path}")
                released = True
            except Exception as e:
                logger.error(f"Partial Lock í•´ì œ ì‹¤íŒ¨: {e}")
    
    # NFS sync
    if released:
        time.sleep(1)
    
    return released
```

### 4.6 ë™ì¼ ì‚¬ìš©ì ê¸°ì¡´ Lock ìë™ í•´ì œ

```python
def release_existing_user_locks(file_path: str, user: str):
    """
    ê°™ì€ íŒŒì¼ì— ëŒ€í•œ ë™ì¼ ì‚¬ìš©ìì˜ ê¸°ì¡´ Lock ìë™ í•´ì œ
    
    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - User Aê°€ Partial Lock Aë¥¼ ë³´ìœ 
    - User Aê°€ ê°™ì€ íŒŒì¼ì„ ë‹¤ì‹œ Selective Load
    â†’ ê¸°ì¡´ Lock Aë¥¼ ìë™ í•´ì œí•˜ê³  ìƒˆ Lock ìƒì„±
    """
    release_lock(file_path, user)
```

---

## 5. Merge Update ìƒì„¸ ëª…ì„¸

### 5.1 Merge Update ê°œìš”

**ëª©ì :** Partial Lockìœ¼ë¡œ ì‘ì—…í•œ ì˜ì—­ë§Œ ì›ë³¸ Parquetì— ë³‘í•©í•˜ì—¬ ì €ì¥

**í•µì‹¬ ì›ì¹™:**

1. ìˆ˜ì •ëœ uniqidë§Œ ì—…ë°ì´íŠ¸
2. ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ì‘ì—…í•œ ì˜ì—­ì€ ë³´ì¡´
3. Atomic êµì²´ë¡œ ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥
4. ë™ì‹œ ì €ì¥ ë°©ì§€ (.merge.lock)

### 5.2 Merge Update ì•Œê³ ë¦¬ì¦˜

```python
def merge_update_safe(file_path: str, modified_df: pl.DataFrame, locked_uniqids: List[int], user: str) -> Tuple[bool, str]:
    """
    ì•ˆì „í•œ Merge Update (ë™ì‹œì„± ì œì–´ í¬í•¨)
    
    Args:
        file_path: ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ
        modified_df: ìˆ˜ì •ëœ DataFrame (SSDF.dataframe)
        locked_uniqids: ë‚´ê°€ Lockí•œ uniqid ë¦¬ìŠ¤íŠ¸
        user: ì €ì¥í•˜ëŠ” ì‚¬ìš©ì
    
    Returns:
        (success: bool, message: str)
    
    ì•Œê³ ë¦¬ì¦˜:
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    1. Merge Lock íšë“ (.merge.lock íŒŒì¼ ìƒì„±, ìµœëŒ€ 10ì´ˆ ëŒ€ê¸°)
    2. ë°±ì—… ìƒì„± (backup/result_v{N}_{timestamp}.parquet)
    3. ì›ë³¸ Parquet ì½ê¸°
    4. Merge ìˆ˜í–‰:
       - ë°©ë²• A: Polars update() ì‚¬ìš©
       - ë°©ë²• B: filter + concat + sort
    5. ì„ì‹œ íŒŒì¼ì— ì €ì¥ (result.parquet.tmp)
    6. Atomic rename (os.replace)
    7. .version íŒŒì¼ ì—…ë°ì´íŠ¸
    8. .meta íŒŒì¼ ì—…ë°ì´íŠ¸ (gen_waive_metadata)
    9. Merge Lock í•´ì œ
    10. NFS sync
    
    ì‹¤íŒ¨ ì‹œ:
    - Rollback: ë°±ì—…ì—ì„œ ë³µì›
    - Merge Lock í•´ì œ
    - ì—ëŸ¬ ë¡œê·¸ + ê´€ë¦¬ì ì•Œë¦¼
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    """
    actual_path = convert_to_actual_path(file_path)
    basename = os.path.splitext(os.path.basename(actual_path))[0]
    directory = os.path.dirname(actual_path)
    merge_lock_path = os.path.join(directory, f"{basename}.merge.lock")
    
    # Step 1: Merge Lock íšë“
    acquired = try_acquire_merge_lock(merge_lock_path, timeout=10)
    if not acquired:
        return False, "ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ì €ì¥ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
    
    backup_path = None
    
    try:
        # Step 2: ë°±ì—… ìƒì„±
        backup_path = create_version_backup(actual_path)
        
        # Step 3: ì›ë³¸ ì½ê¸°
        original_df = pl.read_parquet(actual_path)
        
        # Step 4: Merge ìˆ˜í–‰
        merged_df = perform_merge(original_df, modified_df, locked_uniqids)
        
        # Step 5: ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = f"{actual_path}.tmp"
        merged_df.write_parquet(temp_path)
        
        # Step 6: Atomic rename
        os.replace(temp_path, actual_path)
        os.chmod(actual_path, 0o777)
        
        # Step 7: .version ì—…ë°ì´íŠ¸
        update_version_file(actual_path, backup_path, user, "partial_save", filter_expr=None)
        
        # Step 8: .meta ì—…ë°ì´íŠ¸
        update_metadata_with_waive(actual_path, merged_df)
        
        # Step 9: Merge Lock í•´ì œ
        release_merge_lock(merge_lock_path)
        
        # Step 10: NFS sync
        time.sleep(1)
        
        logger.info(f"Merge Update ì„±ê³µ: {actual_path}")
        return True, "ì €ì¥ ì™„ë£Œ"
    
    except Exception as e:
        logger.error(f"Merge Update ì‹¤íŒ¨: {e}")
        
        # Rollback
        if backup_path and os.path.exists(backup_path):
            try:
                shutil.copy(backup_path, actual_path)
                logger.info(f"Rollback ì™„ë£Œ: {backup_path} â†’ {actual_path}")
            except Exception as rollback_error:
                logger.critical(f"Rollback ì‹¤íŒ¨: {rollback_error}")
                # ê´€ë¦¬ì ì•Œë¦¼ (êµ¬í˜„ ë°©ë²•ì€ ì‹œìŠ¤í…œì— ë§ê²Œ)
                notify_admin(f"CRITICAL: Rollback ì‹¤íŒ¨ {actual_path}")
        
        # Merge Lock í•´ì œ
        release_merge_lock(merge_lock_path)
        
        return False, f"ì €ì¥ ì‹¤íŒ¨: {str(e)}"
```

### 5.3 Merge ë°©ë²• êµ¬í˜„

```python
def perform_merge(original_df: pl.DataFrame, modified_df: pl.DataFrame, locked_uniqids: List[int]) -> pl.DataFrame:
    """
    DataFrame Merge ìˆ˜í–‰
    
    ë‘ ê°€ì§€ ë°©ë²• ë¹„êµ:
    - ë°©ë²• A: Polars update() (ì¶”ì²œ)
    - ë°©ë²• B: filter + concat + sort
    
    ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í›„ ë¹ ë¥¸ ë°©ë²• ì±„íƒ
    """
    # ë°©ë²• A: Polars update() (Polars 0.20.0+)
    try:
        merged_df = original_df.update(
            modified_df.filter(pl.col("uniqid").is_in(locked_uniqids)),
            on="uniqid"
        )
        return merged_df
    except Exception as e:
        logger.warning(f"update() ì‹¤íŒ¨, concat ë°©ì‹ ì‚¬ìš©: {e}")
    
    # ë°©ë²• B: filter + concat + sort
    # 1. ìˆ˜ì •ëœ í–‰ë§Œ ì¶”ì¶œ
    modified_rows = modified_df.filter(pl.col("uniqid").is_in(locked_uniqids))
    
    # 2. ì›ë³¸ì—ì„œ ìˆ˜ì •ë˜ì§€ ì•Šì€ í–‰ ì¶”ì¶œ
    unchanged_rows = original_df.filter(~pl.col("uniqid").is_in(locked_uniqids))
    
    # 3. Concat
    merged_df = pl.concat([modified_rows, unchanged_rows])
    
    # 4. Sort
    merged_df = merged_df.sort("uniqid")
    
    return merged_df
```

### 5.4 Merge Lock ê´€ë¦¬

```python
def try_acquire_merge_lock(lock_path: str, timeout: int = 10) -> bool:
    """
    Merge Lock íšë“ ì‹œë„ (ìµœëŒ€ timeoutì´ˆ ëŒ€ê¸°)
    
    Returns:
        bool: íšë“ ì„±ê³µ ì—¬ë¶€
    """
    start_time = time.time()
    
    while time.time() - start_time < timeout:
        if not os.path.exists(lock_path):
            try:
                # Lock íŒŒì¼ ìƒì„±
                with open(lock_path, 'w') as f:
                    json.dump({
                        "user": CONFIG.USERNAME,
                        "acquired_at": datetime.now().isoformat(),
                    }, f)
                
                os.chmod(lock_path, 0o777)
                
                # NFS sync
                time.sleep(0.5)
                
                # ìƒì„± í™•ì¸
                if os.path.exists(lock_path):
                    logger.info(f"Merge Lock íšë“: {lock_path}")
                    return True
            except Exception as e:
                logger.warning(f"Merge Lock íšë“ ì‹œë„ ì‹¤íŒ¨: {e}")
        
        # 0.5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
        time.sleep(0.5)
    
    logger.error(f"Merge Lock íšë“ íƒ€ì„ì•„ì›ƒ: {lock_path}")
    return False


def release_merge_lock(lock_path: str):
    """
    Merge Lock í•´ì œ
    """
    if os.path.exists(lock_path):
        try:
            os.remove(lock_path)
            logger.info(f"Merge Lock í•´ì œ: {lock_path}")
        except Exception as e:
            logger.error(f"Merge Lock í•´ì œ ì‹¤íŒ¨: {e}")
```

### 5.5 ì €ì¥ ì‹œ í˜¸ì¶œ ì§€ì 

```python
# components/menu/home/item/save.py

@app.callback(
    Output("toaster", "children", allow_duplicate=True),
    Input("save-to-workspace-button", "n_clicks"),
    prevent_initial_call=True,
)
def save_to_workspace(n_clicks):
    """
    WORKSPACE ì €ì¥ (Merge Update ì‚¬ìš©)
    """
    if not n_clicks:
        return no_update
    
    # Read Mode ì²´í¬
    if SSDF.readonly:
        toast = dbpc.Toast(
            message="Read Modeì—ì„œëŠ” WORKSPACEì— ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            intent="warning",
            icon="warning-sign",
        )
        return [toast]
    
    file_path = SSDF.file_path
    modified_df = SSDF.dataframe
    
    # Lock ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    locks = scan_all_locks(file_path)
    my_lock = next((lock for lock in locks if lock["user"] == CONFIG.USERNAME), None)
    
    if not my_lock:
        toast = dbpc.Toast(
            message="Lockì´ ì—†ìŠµë‹ˆë‹¤. ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            intent="danger",
            icon="error",
        )
        return [toast]
    
    # Full Lock vs Partial Lock
    if my_lock["type"] == "full":
        # ì „ì²´ ë®ì–´ì“°ê¸°
        success = save_full(file_path, modified_df, CONFIG.USERNAME)
    else:
        # Merge Update
        success, message = merge_update_safe(
            file_path,
            modified_df,
            my_lock["locked_uniqids"],
            CONFIG.USERNAME
        )
    
    if success:
        toast = dbpc.Toast(
            message="ì €ì¥ ì™„ë£Œ",
            intent="success",
            icon="tick",
        )
    else:
        toast = dbpc.Toast(
            message=f"ì €ì¥ ì‹¤íŒ¨: {message}",
            intent="danger",
            icon="error",
        )
    
    return [toast]
```

---

## 6. Version Management ìƒì„¸ ëª…ì„¸

### 6.1 ë²„ì „ ë°±ì—… ìƒì„±

```python
def create_version_backup(file_path: str) -> str:
    """
    ë²„ì „ ë°±ì—… ìƒì„±
    
    Args:
        file_path: ì›ë³¸ Parquet íŒŒì¼ ê²½ë¡œ
    
    Returns:
        str: ë°±ì—… íŒŒì¼ ê²½ë¡œ
    
    ë¡œì§:
    1. backup/ í´ë” ìƒì„± (ì—†ìœ¼ë©´)
    2. .version íŒŒì¼ ì½ê¸° â†’ ë‹¤ìŒ ë²„ì „ ë²ˆí˜¸ ê³„ì‚°
    3. {basename}_v{N}_{timestamp}.parquetë¡œ ë³µì‚¬
    4. chmod 0o777
    """
    actual_path = convert_to_actual_path(file_path)
    basename = os.path.splitext(os.path.basename(actual_path))[0]
    directory = os.path.dirname(actual_path)
    backup_dir = os.path.join(directory, "backup")
    
    # backup/ í´ë” ìƒì„±
    os.makedirs(backup_dir, exist_ok=True)
    
    # ë‹¤ìŒ ë²„ì „ ë²ˆí˜¸
    version_file_path = os.path.join(directory, f"{basename}.version")
    next_version = get_next_version_number(version_file_path)
    
    # ë°±ì—… íŒŒì¼ëª…
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_filename = f"{basename}_v{next_version}_{timestamp}.parquet"
    backup_path = os.path.join(backup_dir, backup_filename)
    
    # ë³µì‚¬
    shutil.copy(actual_path, backup_path)
    os.chmod(backup_path, 0o777)
    
    logger.info(f"ë²„ì „ ë°±ì—… ìƒì„±: {backup_path}")
    return backup_path


def get_next_version_number(version_file_path: str) -> int:
    """
    ë‹¤ìŒ ë²„ì „ ë²ˆí˜¸ ê³„ì‚°
    """
    if not os.path.exists(version_file_path):
        return 1
    
    try:
        with open(version_file_path, 'r') as f:
            version_data = json.load(f)
        return version_data.get("current_version", 0) + 1
    except Exception as e:
        logger.warning(f".version íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return 1
```

### 6.2 .version íŒŒì¼ ì—…ë°ì´íŠ¸

```python
def update_version_file(
    file_path: str,
    backup_path: str,
    user: str,
    action: str,
    filter_expr: str = None
):
    """
    .version íŒŒì¼ ì—…ë°ì´íŠ¸
    
    Args:
        file_path: ì›ë³¸ íŒŒì¼ ê²½ë¡œ
        backup_path: ë°±ì—… íŒŒì¼ ê²½ë¡œ
        user: ì €ì¥í•œ ì‚¬ìš©ì
        action: "full_save" | "partial_save"
        filter_expr: Partial Saveì¸ ê²½ìš° í•„í„° ì¡°ê±´
    """
    actual_path = convert_to_actual_path(file_path)
    basename = os.path.splitext(os.path.basename(actual_path))[0]
    directory = os.path.dirname(actual_path)
    version_file_path = os.path.join(directory, f"{basename}.version")
    
    # ê¸°ì¡´ ë²„ì „ ì •ë³´ ì½ê¸°
    if os.path.exists(version_file_path):
        with open(version_file_path, 'r') as f:
            version_data = json.load(f)
    else:
        version_data = {
            "current_version": 0,
            "history": []
        }
    
    # ìƒˆ ë²„ì „ ì¶”ê°€
    new_version = version_data["current_version"] + 1
    backup_filename = os.path.basename(backup_path)
    
    history_entry = {
        "version": new_version,
        "backup_file": backup_filename,
        "created_by": user,
        "created_at": datetime.now().isoformat(),
        "action": action,
        "filter_expr": filter_expr,
        "description": f"{action} by {user}",
    }
    
    version_data["current_version"] = new_version
    version_data["history"].append(history_entry)
    
    # ì €ì¥
    with open(version_file_path, 'w') as f:
        json.dump(version_data, f, indent=2)
    
    os.chmod(version_file_path, 0o777)
    
    logger.info(f".version ì—…ë°ì´íŠ¸: v{new_version}")
```

### 6.3 Version Viewer UI

```python
# components/menu/home/item/workspace/version_viewer.py

def create_version_viewer_layout():
    """
    ë²„ì „ ë·°ì–´ UI
    """
    return dmc.Modal(
        id="version-viewer-modal",
        title="Version History",
        size="xl",
        children=[
            dmc.Stack([
                # ë²„ì „ í…Œì´ë¸”
                html.Div(id="version-table-container"),
                
                # ì•¡ì…˜ ë²„íŠ¼
                dmc.Group([
                    dmc.Button(
                        "Close",
                        id="version-viewer-close",
                        variant="outline",
                    ),
                ], position="right"),
            ]),
        ],
    )


@app.callback(
    Output("version-viewer-modal", "opened"),
    Output("version-table-container", "children"),
    Input("view-versions-button", "n_clicks"),
    State("current-file-path", "data"),
    prevent_initial_call=True,
)
def open_version_viewer(n_clicks, file_path):
    """
    ë²„ì „ ë·°ì–´ ì—´ê¸°
    """
    if not n_clicks:
        return no_update, no_update
    
    # .version íŒŒì¼ ì½ê¸°
    versions = load_version_history(file_path)
    
    # í…Œì´ë¸” ìƒì„±
    table = create_version_table(versions, file_path)
    
    return True, table


def create_version_table(versions: List[dict], file_path: str):
    """
    ë²„ì „ í…Œì´ë¸” ìƒì„±
    """
    rows = []
    
    for v in reversed(versions):  # ìµœì‹  ë²„ì „ë¶€í„°
        is_current = (v["version"] == versions[-1]["version"])
        
        row = html.Tr([
            html.Td(f"v{v['version']}" + (" (Current)" if is_current else "")),
            html.Td(v["created_by"]),
            html.Td(v["created_at"][:19]),  # ì´ˆê¹Œì§€ë§Œ
            html.Td(v["action"]),
            html.Td(v.get("filter_expr", "-")),
            html.Td([
                dmc.Button(
                    "Restore",
                    id={"type": "restore-version", "version": v["version"]},
                    size="xs",
                    color="orange",
                    disabled=is_current,
                ),
                dmc.Button(
                    "Download",
                    id={"type": "download-version", "version": v["version"]},
                    size="xs",
                    variant="light",
                    style={"marginLeft": "5px"},
                ),
            ]),
        ])
        rows.append(row)
    
    table = dmc.Table([
        html.Thead([
            html.Tr([
                html.Th("Version"),
                html.Th("Saved By"),
                html.Th("Saved At"),
                html.Th("Action"),
                html.Th("Filter"),
                html.Th("Actions"),
            ]),
        ]),
        html.Tbody(rows),
    ], striped=True, highlightOnHover=True)
    
    return table
```

### 6.4 ë²„ì „ ë³µì›

```python
@app.callback(
    Output("toaster", "children", allow_duplicate=True),
    Output("version-viewer-modal", "opened", allow_duplicate=True),
    Input({"type": "restore-version", "version": ALL}, "n_clicks"),
    State("current-file-path", "data"),
    prevent_initial_call=True,
)
def restore_version(n_clicks, file_path):
    """
    ë²„ì „ ë³µì›
    
    ë¡œì§:
    1. Lock í™•ì¸ â†’ ìˆìœ¼ë©´ ë³µì› ë¶ˆê°€
    2. ë°±ì—… íŒŒì¼ ë³µì‚¬
    3. .meta ì—…ë°ì´íŠ¸
    4. Toast ì•Œë¦¼
    """
    if not any(n_clicks):
        return no_update, no_update
    
    version = ctx.triggered_id["version"]
    
    # Lock í™•ì¸
    locks = scan_all_locks(file_path)
    if len(locks) > 0:
        toast = dbpc.Toast(
            message="íŒŒì¼ì´ Lockë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € Lockì„ í•´ì œí•˜ì„¸ìš”.",
            intent="warning",
            icon="warning-sign",
        )
        return [toast], no_update
    
    # ë³µì› ìˆ˜í–‰
    try:
        success = perform_version_restore(file_path, version)
        
        if success:
            toast = dbpc.Toast(
                message=f"v{version}ìœ¼ë¡œ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤.",
                intent="success",
                icon="tick",
            )
            return [toast], False  # Modal ë‹«ê¸°
        else:
            toast = dbpc.Toast(
                message="ë³µì› ì‹¤íŒ¨",
                intent="danger",
                icon="error",
            )
            return [toast], no_update
    
    except Exception as e:
        logger.error(f"ë²„ì „ ë³µì› ì‹¤íŒ¨: {e}")
        toast = dbpc.Toast(
            message=f"ë³µì› ì‹¤íŒ¨: {str(e)}",
            intent="danger",
            icon="error",
        )
        return [toast], no_update


def perform_version_restore(file_path: str, version: int) -> bool:
    """
    ë²„ì „ ë³µì› ìˆ˜í–‰
    """
    actual_path = convert_to_actual_path(file_path)
    basename = os.path.splitext(os.path.basename(actual_path))[0]
    directory = os.path.dirname(actual_path)
    
    # .version íŒŒì¼ì—ì„œ ë°±ì—… íŒŒì¼ëª… ì°¾ê¸°
    version_file_path = os.path.join(directory, f"{basename}.version")
    
    with open(version_file_path, 'r') as f:
        version_data = json.load(f)
    
    target_version = next(
        (v for v in version_data["history"] if v["version"] == version),
        None
    )
    
    if not target_version:
        raise Exception(f"ë²„ì „ {version}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    backup_filename = target_version["backup_file"]
    backup_path = os.path.join(directory, "backup", backup_filename)
    
    if not os.path.exists(backup_path):
        raise Exception(f"ë°±ì—… íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {backup_path}")
    
    # í˜„ì¬ ë²„ì „ ë°±ì—… (ë³µì› ì „)
    current_backup = create_version_backup(actual_path)
    
    # ë³µì›
    shutil.copy(backup_path, actual_path)
    os.chmod(actual_path, 0o777)
    
    # .meta ì—…ë°ì´íŠ¸
    df = pl.read_parquet(actual_path)
    update_metadata_with_waive(actual_path, df)
    
    # NFS sync
    time.sleep(1)
    
    logger.info(f"ë²„ì „ ë³µì› ì™„ë£Œ: v{version}")
    return True
```

---

## 7. ì—ëŸ¬ ì²˜ë¦¬ ë° ì˜ˆì™¸ ìƒí™©

### 7.1 ì—ëŸ¬ ë¶„ë¥˜

```python
# ì—ëŸ¬ ìœ í˜•ë³„ ì²˜ë¦¬ ë°©ì‹

ERROR_TYPES = {
    # ì¹˜ëª…ì  ì—ëŸ¬ (Modal Dialog)
    "CRITICAL": {
        "LOCK_CONFLICT": "ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ì´ë¯¸ ì´ ì˜ì—­ì„ í¸ì§‘ ì¤‘ì…ë‹ˆë‹¤.",
        "FULL_LOCK_EXISTS": "íŒŒì¼ì´ {user}ì— ì˜í•´ ì™„ì „íˆ ì ê²¨ìˆìŠµë‹ˆë‹¤.",
        "FILTER_SYNTAX_ERROR": "í•„í„° ì¡°ê±´ ë¬¸ë²•ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        "NFS_SYNC_FAILED": "ë„¤íŠ¸ì›Œí¬ ë™ê¸°í™” ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "MERGE_CONFLICT": "ì €ì¥ ì¤‘ ì¶©ëŒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë°±ì—…ì„ í™•ì¸í•˜ì„¸ìš”.",
        "EDITING_ANOTHER_FILE": "í˜„ì¬ ë‹¤ë¥¸ íŒŒì¼ì„ í¸ì§‘ ì¤‘ì…ë‹ˆë‹¤. ë¨¼ì € ì €ì¥í•˜ê±°ë‚˜ Read Modeë¡œ ì „í™˜í•˜ì„¸ìš”.",
    },
    
    # ê²½ê³  (Toast, ìë™ ì‚¬ë¼ì§)
    "WARNING": {
        "READ_MODE_SAVE": "Read Modeì—ì„œëŠ” WORKSPACEì— ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "NO_LOCK": "Lockì´ ì—†ìŠµë‹ˆë‹¤. ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "LOCK_RELEASE_FAILED": "Lock í•´ì œ ì‹¤íŒ¨. ìˆ˜ë™ìœ¼ë¡œ í•´ì œí•˜ì„¸ìš”.",
    },
    
    # ì •ë³´ (Toast)
    "INFO": {
        "LOCK_ACQUIRED": "Lock íšë“ ì™„ë£Œ",
        "DATA_LOADED": "ë°ì´í„° ë¡œë”© ì™„ë£Œ: {rows} rows",
        "SAVED": "ì €ì¥ ì™„ë£Œ",
    },
}
```

### 7.2 ì—ëŸ¬ í•¸ë“¤ëŸ¬

```python
def handle_error(error_code: str, **kwargs) -> dbpc.Toast:
    """
    ì—ëŸ¬ ì½”ë“œì— ë”°ë¥¸ Toast ìƒì„±
    
    Args:
        error_code: ì—ëŸ¬ ì½”ë“œ ("LOCK_CONFLICT" ë“±)
        **kwargs: ë©”ì‹œì§€ í¬ë§·ìš© ë³€ìˆ˜
    
    Returns:
        dbpc.Toast
    """
    # ì—ëŸ¬ íƒ€ì… ì°¾ê¸°
    error_type = None
    message = None
    
    for etype, errors in ERROR_TYPES.items():
        if error_code in errors:
            error_type = etype
            message = errors[error_code].format(**kwargs)
            break
    
    if not message:
        message = f"ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬: {error_code}"
        error_type = "CRITICAL"
    
    # Toast ìƒì„±
    if error_type == "CRITICAL":
        intent = "danger"
        icon = "error"
    elif error_type == "WARNING":
        intent = "warning"
        icon = "warning-sign"
    else:
        intent = "primary"
        icon = "info-sign"
    
    return dbpc.Toast(
        message=message,
        intent=intent,
        icon=icon,
        timeout=5000 if error_type != "CRITICAL" else 0,  # ì¹˜ëª…ì  ì—ëŸ¬ëŠ” ìë™ ë‹«ê¸° X
    )


# ì‚¬ìš© ì˜ˆì‹œ
toast = handle_error("LOCK_CONFLICT")
toast = handle_error("FULL_LOCK_EXISTS", user="deepwonwoo")
toast = handle_error("DATA_LOADED", rows=45000)
```

### 7.3 ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬

#### 1. í˜„ì¬ ë‹¤ë¥¸ íŒŒì¼ í¸ì§‘ ì¤‘

```python
def check_current_edit_mode() -> Tuple[bool, str]:
    """
    í˜„ì¬ ResultViewerê°€ Edit Modeì¸ì§€ í™•ì¸
    
    Returns:
        (is_editing: bool, message: str)
    """
    if SSDF.get_current_mode() == "edit":
        return True, "í˜„ì¬ ë‹¤ë¥¸ íŒŒì¼ì„ í¸ì§‘ ì¤‘ì…ë‹ˆë‹¤."
    return False, ""


# Selective Loading Dialog ì—´ê¸° ì „ ì²´í¬
is_editing, msg = check_current_edit_mode()
if is_editing:
    return handle_error("EDITING_ANOTHER_FILE")
```

#### 2. ë„¤íŠ¸ì›Œí¬ ì§€ì—° (NFS)

```python
def safe_nfs_operation(operation_func, *args, **kwargs):
    """
    NFS ì‘ì—… ë˜í¼ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    
    Args:
        operation_func: ì‹¤í–‰í•  í•¨ìˆ˜
        *args, **kwargs: í•¨ìˆ˜ ì¸ì
    
    Returns:
        í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼
    """
    max_retries = 3
    retry_delay = 1  # ì´ˆ
    
    for attempt in range(max_retries):
        try:
            result = operation_func(*args, **kwargs)
            
            # NFS sync
            time.sleep(1)
            
            return result
        
        except Exception as e:
            if attempt < max_retries - 1:
                logger.warning(f"NFS ì‘ì—… ì¬ì‹œë„ ({attempt + 1}/{max_retries}): {e}")
                time.sleep(retry_delay)
            else:
                logger.error(f"NFS ì‘ì—… ì‹¤íŒ¨: {e}")
                raise


# ì‚¬ìš© ì˜ˆì‹œ
safe_nfs_operation(os.remove, lock_path)
```

#### 3. Lock íŒŒì¼ ì†ìƒ

```python
def validate_lock_file(lock_path: str) -> Tuple[bool, dict]:
    """
    Lock íŒŒì¼ ê²€ì¦
    
    Returns:
        (is_valid: bool, lock_data: dict)
    """
    try:
        with open(lock_path, 'r') as f:
            lock_data = json.load(f)
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ["user", "type", "locked_at"]
        for field in required_fields:
            if field not in lock_data:
                logger.warning(f"Lock íŒŒì¼ ì†ìƒ: {lock_path}, í•„ë“œ ëˆ„ë½ {field}")
                return False, {}
        
        return True, lock_data
    
    except Exception as e:
        logger.warning(f"Lock íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {lock_path}, {e}")
        return False, {}


# scan_all_locksì—ì„œ ì‚¬ìš©
is_valid, lock_data = validate_lock_file(lock_path)
if is_valid:
    locks.append(lock_data)
else:
    # ì†ìƒëœ Lock ë¬´ì‹œ
    pass
```

#### 4. Rollback ì‹¤íŒ¨

```python
def notify_admin(message: str):
    """
    ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼ ì „ì†¡
    
    êµ¬í˜„ ë°©ë²•:
    - devworks_api.pyë¥¼ í†µí•œ ë©”ì‹œì§€ ì „ì†¡
    - ë˜ëŠ” ì—ëŸ¬ ë¡œê·¸ íŒŒì¼ì— CRITICAL ë ˆë²¨ ê¸°ë¡
    """
    logger.critical(f"[ADMIN ALERT] {message}")
    
    # DevWorks ë©”ì‹œì§€ ì „ì†¡ (êµ¬í˜„ë˜ì–´ ìˆë‹¤ë©´)
    try:
        from utils.devworks_api import send_message
        send_message(
            recipient="admin@company.com",
            subject="ResultViewer CRITICAL ERROR",
            body=message,
        )
    except Exception as e:
        logger.error(f"ê´€ë¦¬ì ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
```

---

## 8. ì„±ëŠ¥ ìµœì í™” ë° í…ŒìŠ¤íŠ¸ ì „ëµ

### 8.1 ì„±ëŠ¥ ìµœì í™”

#### 1. Polars Lazy Evaluation

```python
# âŒ ë¹„íš¨ìœ¨ì 
df = pl.read_parquet(file_path)
filtered_df = df.filter(col("Part").eq("CPU"))
row_count = len(filtered_df)

# âœ… íš¨ìœ¨ì  (Lazy Evaluation)
row_count = pl.scan_parquet(file_path) \
              .filter(col("Part").eq("CPU")) \
              .select(pl.count()) \
              .collect().item()
```

#### 2. ì»¬ëŸ¼ ì„ íƒ ìµœì í™”

```python
# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì½ê¸°
df = pl.scan_parquet(file_path, columns=["uniqid", "waiver", "Part"]) \
       .collect()
```

#### 3. Merge Update ìµœì í™”

```python
# update() vs concat() ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
import time

def benchmark_merge_methods(original_df, modified_df, uniqids):
    # ë°©ë²• A: update()
    start = time.time()
    result_a = original_df.update(
        modified_df.filter(pl.col("uniqid").is_in(uniqids)),
        on="uniqid"
    )
    time_a = time.time() - start
    
    # ë°©ë²• B: concat()
    start = time.time()
    modified_rows = modified_df.filter(pl.col("uniqid").is_in(uniqids))
    unchanged_rows = original_df.filter(~pl.col("uniqid").is_in(uniqids))
    result_b = pl.concat([modified_rows, unchanged_rows]).sort("uniqid")
    time_b = time.time() - start
    
    logger.info(f"update(): {time_a:.3f}s, concat(): {time_b:.3f}s")
    
    # ë¹ ë¥¸ ë°©ë²• ë°˜í™˜
    return result_a if time_a < time_b else result_b
```

### 8.2 í…ŒìŠ¤íŠ¸ ì „ëµ

#### 1. E2E í…ŒìŠ¤íŠ¸ (Playwright MCP)

**í•„ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:**

```python
# tests/test_selective_loading.py

def test_selective_loading_basic():
    """
    ê¸°ë³¸ Selective Loading í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. ResultViewer ì‹¤í–‰
    2. WORKSPACE Explorer ì—´ê¸°
    3. íŒŒì¼ í´ë¦­ â†’ Dialog í‘œì‹œ í™•ì¸
    4. Lock ëª¨ë“œ ì„ íƒ (Read-Only)
    5. Load Data í´ë¦­
    6. Gridì— ë°ì´í„° í‘œì‹œ í™•ì¸
    """
    pass


def test_partial_lock_acquisition():
    """
    Partial Lock íšë“ í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. User A: CPU ë°ì´í„° Partial Lock íšë“
    2. Lock íŒŒì¼ ìƒì„± í™•ì¸
    3. User B (ë‹¤ë¥¸ Python ì¸ìŠ¤í„´ìŠ¤): GPU ë°ì´í„° Partial Lock íšë“ (ì„±ê³µ)
    4. User C: CPU ë°ì´í„° Partial Lock ì‹œë„ (ì‹¤íŒ¨)
    """
    pass


def test_merge_update():
    """
    Merge Update í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. User A: CPU ë°ì´í„° í¸ì§‘ í›„ ì €ì¥
    2. User B: GPU ë°ì´í„° í¸ì§‘ í›„ ì €ì¥
    3. ì›ë³¸ íŒŒì¼ì— ë‘ ì‚¬ìš©ì ë³€ê²½ì‚¬í•­ ëª¨ë‘ ë°˜ì˜ í™•ì¸
    4. ë°±ì—… íŒŒì¼ ìƒì„± í™•ì¸
    5. .version íŒŒì¼ ì—…ë°ì´íŠ¸ í™•ì¸
    """
    pass


def test_lock_conflict():
    """
    Lock ì¶©ëŒ í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. User A: Full Lock íšë“
    2. User B: Partial Lock ì‹œë„ â†’ ì‹¤íŒ¨ ë©”ì‹œì§€ í™•ì¸
    3. User A: Lock í•´ì œ
    4. User B: Partial Lock ì¬ì‹œë„ â†’ ì„±ê³µ
    """
    pass


def test_version_restore():
    """
    ë²„ì „ ë³µì› í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. ë°ì´í„° ìˆ˜ì • ë° ì €ì¥ (v1, v2, v3 ìƒì„±)
    2. Version Viewer ì—´ê¸°
    3. v1ìœ¼ë¡œ ë³µì›
    4. ë°ì´í„° í™•ì¸
    """
    pass
```

#### 2. ë‹¤ì¤‘ ì‚¬ìš©ì ì‹œë®¬ë ˆì´ì…˜

```python
# tests/test_concurrent_access.py

import subprocess
import time

def test_concurrent_partial_locks():
    """
    ë‹¤ì¤‘ Python ì¸ìŠ¤í„´ìŠ¤ë¡œ ë™ì‹œ ì ‘ì† í…ŒìŠ¤íŠ¸
    """
    # User A ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘
    process_a = subprocess.Popen([
        "python", "app.py",
        "--username", "user_a",
        "--port", "8050"
    ])
    
    time.sleep(5)  # ì´ˆê¸°í™” ëŒ€ê¸°
    
    # User B ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘
    process_b = subprocess.Popen([
        "python", "app.py",
        "--username", "user_b",
        "--port", "8051"
    ])
    
    time.sleep(5)
    
    # Playwrightë¡œ ë‘ ë¸Œë¼ìš°ì € ì œì–´
    # ...
    
    # í…ŒìŠ¤íŠ¸ í›„ ì •ë¦¬
    process_a.terminate()
    process_b.terminate()
```

#### 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

```python
# tests/test_performance.py

def test_large_file_loading():
    """
    ëŒ€ìš©ëŸ‰ íŒŒì¼ ë¡œë”© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    
    ëª©í‘œ:
    - 1GB Parquet â†’ 5ì´ˆ ì´ë‚´ ë©”íƒ€ì •ë³´ í‘œì‹œ
    - í•„í„°ë§ (10ë§Œ í–‰ â†’ 1ë§Œ í–‰) â†’ 10ì´ˆ ì´ë‚´
    """
    pass


def test_merge_update_performance():
    """
    Merge Update ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    
    ëª©í‘œ:
    - 1ì–µ í–‰ DataFrameì—ì„œ 1ë§Œ í–‰ ë³‘í•© â†’ 30ì´ˆ ì´ë‚´
    """
    pass
```

### 8.3 ë¡œë”© í‘œì‹œ (UX)

**í•„ìˆ˜:** ì‹œê°„ì´ ê±¸ë¦¬ëŠ” ëª¨ë“  ì‘ì—…ì— ë¡œë”© í‘œì‹œ

```python
# ë¡œë”© í‘œì‹œ íŒ¨í„´

# 1. aggrid-overlay ì‚¬ìš© (ì „ì²´ í™”ë©´)
@app.callback(
    Output("aggrid-overlay", "visible"),
    Input("some-button", "n_clicks"),
)
def show_loading(n_clicks):
    # ì‘ì—… ì‹œì‘
    return True
    
    # ì‘ì—… ì™„ë£Œ í›„
    return False


# 2. dmc.Loader ì‚¬ìš© (ë¶€ë¶„ ì˜ì—­)
dmc.LoadingOverlay(
    visible=True,
    loaderProps={"variant": "dots", "color": "blue"},
    children=[
        html.Div(id="content-area")
    ],
)


# 3. Progress Bar
dmc.Progress(
    value=progress_percent,
    label=f"{progress_percent}%",
    size="xl",
    radius="xl",
    striped=True,
    animate=True,
)
```







# WORKSPACE 2.0 ìƒì„¸ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

## 1. ê¸°ëŠ¥ë³„ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

### 1.1 File Lock ê´€ë¦¬ í…ŒìŠ¤íŠ¸

```python
def test_file_lock_lifecycle():
    """
    Lock íŒŒì¼ ìƒëª…ì£¼ê¸° í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. Read Modeë¡œ íŒŒì¼ ì—´ê¸° â†’ .lock íŒŒì¼ ë¯¸ìƒì„± í™•ì¸
    2. Edit Mode ì „í™˜ â†’ .lock íŒŒì¼ ìƒì„± í™•ì¸
    3. Lock íŒŒì¼ ë‚´ìš© ê²€ì¦ (username, timestamp, pid)
    4. Read Mode ì „í™˜ â†’ .lock íŒŒì¼ ì‚­ì œ í™•ì¸
    5. ë¹„ì •ìƒ ì¢…ë£Œ ì‹œë®¬ë ˆì´ì…˜ â†’ orphaned lock í™•ì¸
    6. ì•± ì¬ì‹œì‘ â†’ orphaned lock ìë™ ì •ë¦¬ í™•ì¸
    """
    
def test_lock_conflict_resolution():
    """
    Lock ì¶©ëŒ í•´ê²° í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. User A: íŒŒì¼ì„ Edit Modeë¡œ ì—´ê¸°
    2. User B: ê°™ì€ íŒŒì¼ Edit Mode ì‹œë„
    3. ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸: "íŒŒì¼ì´ {username}ì— ì˜í•´ í¸ì§‘ ì¤‘ì…ë‹ˆë‹¤"
    4. User B: Read Modeë¡œëŠ” ì—´ê¸° ê°€ëŠ¥ í™•ì¸
    5. User A: ì‘ì—… ì™„ë£Œ ë° ëª¨ë“œ ì „í™˜
    6. User B: Edit Mode ì¬ì‹œë„ â†’ ì„±ê³µ
    """

def test_stale_lock_detection():
    """
    Stale Lock ê°ì§€ ë° ì²˜ë¦¬
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. Lock íŒŒì¼ ìƒì„± (í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ìƒíƒœ)
    2. 30ë¶„ ì´ìƒ ê²½ê³¼ ì‹œë®¬ë ˆì´ì…˜
    3. ìƒˆ ì‚¬ìš©ì ì ‘ê·¼ ì‹œ stale lock ê°ì§€
    4. ê´€ë¦¬ì ì•Œë¦¼ ë˜ëŠ” ìë™ í•´ì œ ì˜µì…˜ ì œê³µ
    """
```

### 1.2 ë°ì´í„° ì €ì¥ ë° ë™ê¸°í™” í…ŒìŠ¤íŠ¸

```python
def test_save_to_workspace():
    """
    Workspace ì €ì¥ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. ë°ì´í„° ìˆ˜ì • (10ê°œ ì…€)
    2. Save to Workspace ì‹¤í–‰
    3. ë°±ì—… íŒŒì¼ ìƒì„± í™•ì¸ (backup/*)
    4. ì›ë³¸ íŒŒì¼ ì—…ë°ì´íŠ¸ í™•ì¸
    5. .version íŒŒì¼ ì—…ë°ì´íŠ¸ í™•ì¸
    6. .meta íŒŒì¼ í†µê³„ ì—…ë°ì´íŠ¸ í™•ì¸
    7. ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ì¦‰ì‹œ ë³€ê²½ì‚¬í•­ í™•ì¸ ê°€ëŠ¥
    """

def test_concurrent_save_handling():
    """
    ë™ì‹œ ì €ì¥ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. User A: ëŒ€ìš©ëŸ‰ ë°ì´í„°(1M rows) ì €ì¥ ì‹œì‘
    2. User B: ê°™ì€ íŒŒì¼ ì €ì¥ ì‹œë„ (1ì´ˆ í›„)
    3. Merge lock ëŒ€ê¸° ë©”ì‹œì§€ í™•ì¸
    4. User A ì €ì¥ ì™„ë£Œ
    5. User B ìë™ ì¬ì‹œë„ ë° ì„±ê³µ
    6. ë‘ ì‚¬ìš©ì ë³€ê²½ì‚¬í•­ ëª¨ë‘ ë°˜ì˜ í™•ì¸
    """

def test_save_failure_recovery():
    """
    ì €ì¥ ì‹¤íŒ¨ ë³µêµ¬ í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. ì €ì¥ ì¤‘ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œë®¬ë ˆì´ì…˜
    2. ì„ì‹œ íŒŒì¼(.tmp) ì¡´ì¬ í™•ì¸
    3. ë¡¤ë°± í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
    4. ë°±ì—…ì—ì„œ ë³µì› í™•ì¸
    5. ì‚¬ìš©ìì—ê²Œ ì¬ì‹œë„ ì˜µì…˜ ì œê³µ
    """
```

### 1.3 ëª¨ë“œ ì „í™˜ í…ŒìŠ¤íŠ¸

```python
def test_mode_transition_data_integrity():
    """
    ëª¨ë“œ ì „í™˜ ì‹œ ë°ì´í„° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. Read Modeì—ì„œ ë°ì´í„° ìˆ˜ì • (ë©”ëª¨ë¦¬ë§Œ)
    2. Edit Mode ì „í™˜ ì‹œë„
    3. ê²½ê³  ë©”ì‹œì§€: "Read Modeì˜ ë³€ê²½ì‚¬í•­ì´ ì‚¬ë¼ì§‘ë‹ˆë‹¤"
    4. í™•ì¸ â†’ ì›ë³¸ ë°ì´í„° ë‹¤ì‹œ ë¡œë“œ
    5. ì·¨ì†Œ â†’ Read Mode ìœ ì§€, ìˆ˜ì •ì‚¬í•­ ë³´ì¡´
    """

def test_edit_to_read_transition():
    """
    Edit â†’ Read ëª¨ë“œ ì „í™˜ í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. Edit Modeì—ì„œ ë°ì´í„° ìˆ˜ì •
    2. ì €ì¥í•˜ì§€ ì•Šê³  Read Mode ì „í™˜ ì‹œë„
    3. ê²½ê³ : "ì €ì¥ë˜ì§€ ì•Šì€ ë³€ê²½ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤"
    4. ì €ì¥ í›„ ì „í™˜ / ì €ì¥ ì•ˆí•¨ / ì·¨ì†Œ ì˜µì…˜
    5. ê° ì˜µì…˜ë³„ ë™ì‘ í™•ì¸
    """
```

## 2. í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### 2.1 ë‹¤ì¤‘ ì‚¬ìš©ì í˜‘ì—… ì‹œë‚˜ë¦¬ì˜¤

```python
def test_team_collaboration_workflow():
    """
    ì‹¤ì œ íŒ€ í˜‘ì—… ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. Manager: ìƒˆ í”„ë¡œì íŠ¸ í´ë” ìƒì„± (/D1b/R01/FULLCHIP/DRIVER_KEEPER/)
    2. Engineer A: result.parquet ì—…ë¡œë“œ (10M rows)
    3. Engineer B: íŒŒì¼ ì—´ê¸° (Read Mode) â†’ ë°ì´í„° ë¶„ì„
    4. Engineer A: Edit Modeë¡œ waiver ì»¬ëŸ¼ ìˆ˜ì • ì‹œì‘
    5. Engineer B: Edit Mode ì‹œë„ â†’ ì‹¤íŒ¨ (Already locked)
    6. Engineer A: ìˆ˜ì • ì™„ë£Œ ë° ì €ì¥
    7. Engineer B: ìë™ ìƒˆë¡œê³ ì¹¨ ì•Œë¦¼ â†’ ë°ì´í„° ì¬ë¡œë“œ
    8. Engineer B: Edit Modeë¡œ ì „í™˜ ì„±ê³µ
    9. Manager: Version history í™•ì¸
    10. ëª¨ë“  ë³€ê²½ì‚¬í•­ ì¶”ì  ê°€ëŠ¥ í™•ì¸
    """
```

### 2.2 ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤

```python
def test_large_data_performance():
    """
    ëŒ€ìš©ëŸ‰ ë°ì´í„° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    
    ë°ì´í„°ì…‹:
    - 100M rows Ã— 15 columns Parquet file
    - íŒŒì¼ í¬ê¸°: ~5GB
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. íŒŒì¼ ë©”íƒ€ë°ì´í„° ë¡œë”© ì‹œê°„ ì¸¡ì • (ëª©í‘œ: <2ì´ˆ)
    2. ìƒ˜í”Œ ë°ì´í„° í”„ë¦¬ë·° ë¡œë”© (ëª©í‘œ: <5ì´ˆ)
    3. Full ë°ì´í„° ë¡œë”© ì‹œê°„ ì¸¡ì •
    4. í•„í„°ë§ ì ìš© (10M â†’ 100K rows)
    5. Grid ë Œë”ë§ ì‹œê°„ ì¸¡ì • (ëª©í‘œ: <3ì´ˆ)
    6. ìŠ¤í¬ë¡¤ ì„±ëŠ¥ í™•ì¸ (lag ì—†ìŒ)
    7. í¸ì§‘ ëª¨ë“œ ì „í™˜ ì‹œê°„
    8. 1000ê°œ ì…€ ë™ì‹œ ìˆ˜ì •
    9. ì €ì¥ ì‹œê°„ ì¸¡ì • (ëª©í‘œ: <30ì´ˆ)
    10. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (ëª©í‘œ: <2GB)
    """
```

### 2.3 ì˜¤ë¥˜ ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤

```python
def test_disaster_recovery():
    """
    ì¬í•´ ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. 3ëª…ì˜ ì‚¬ìš©ìê°€ ë™ì‹œ ì‘ì—… ì¤‘
    2. NFS ì—°ê²° ì¼ì‹œ ì¤‘ë‹¨ (10ì´ˆ)
    3. ìë™ ì¬ì—°ê²° ì‹œë„ í™•ì¸
    4. ì‘ì—… ì¤‘ë‹¨ ì—†ì´ ê³„ì† ì§„í–‰
    5. ì—°ê²° ë³µêµ¬ í›„ ìë™ ë™ê¸°í™”
    6. ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
    """

def test_corrupt_file_handling():
    """
    ì†ìƒëœ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    1. Parquet íŒŒì¼ ì¼ë¶€ ì†ìƒ ì‹œë®¬ë ˆì´ì…˜
    2. íŒŒì¼ ì—´ê¸° ì‹œë„
    3. ì—ëŸ¬ ê°ì§€ ë° ì‚¬ìš©ì ì•Œë¦¼
    4. ë°±ì—…ì—ì„œ ë³µì› ì˜µì…˜ ì œê³µ
    5. ë³µì› í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
    6. ì •ìƒ ë™ì‘ í™•ì¸
    """
```

## 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸

### 3.1 ë¶€í•˜ í…ŒìŠ¤íŠ¸

```python
def test_concurrent_user_load():
    """
    ë™ì‹œ ì‚¬ìš©ì ë¶€í•˜ í…ŒìŠ¤íŠ¸
    
    ì‹œë‚˜ë¦¬ì˜¤:
    - 50ëª… ë™ì‹œ ì ‘ì†
    - ê° ì‚¬ìš©ìë³„ ë‹¤ë¥¸ íŒŒì¼ ì‘ì—…
    - 5ëª…ì€ ë™ì¼ íŒŒì¼ Read Mode
    - 10ëª…ì€ ë°ì´í„° í¸ì§‘ ì¤‘
    - ë‚˜ë¨¸ì§€ëŠ” íŒŒì¼ ë¸Œë¼ìš°ì§•
    
    ì¸¡ì • í•­ëª©:
    - ì‘ë‹µ ì‹œê°„
    - CPU/Memory ì‚¬ìš©ëŸ‰
    - Lock ê²½í•© ë°œìƒ ë¹ˆë„
    - ì—ëŸ¬ ë°œìƒë¥ 
    """
```

### 3.2 ë©”ëª¨ë¦¬ ìµœì í™” í…ŒìŠ¤íŠ¸

```python
def test_memory_optimization():
    """
    ë©”ëª¨ë¦¬ ìµœì í™” íš¨ê³¼ ì¸¡ì •
    
    ë¹„êµ ì‹œë‚˜ë¦¬ì˜¤:
    1. ì „ì²´ ë°ì´í„° ë¡œë“œ vs Selective Loading
       - 100M rows ì „ì²´ vs 1M rows í•„í„°ë§
       - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 90% ê°ì†Œ í™•ì¸
    
    2. ì»¬ëŸ¼ ì„ íƒ íš¨ê³¼
       - 50 columns ì „ì²´ vs 10 columns ì„ íƒ
       - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 80% ê°ì†Œ í™•ì¸
    """
```

## 4. ì‚¬ìš©ì ìˆ˜ìš©ì„± í…ŒìŠ¤íŠ¸ (UAT)

### 4.1 ì‹¤ì œ ì—…ë¬´ ì‹œë‚˜ë¦¬ì˜¤

```
1. Signoff ê²°ê³¼ ë¶„ì„ ì›Œí¬í”Œë¡œìš°
   - STAR íˆ´ ê²°ê³¼ íŒŒì¼ ì—…ë¡œë“œ
   - Violation ë°ì´í„° í•„í„°ë§
   - Waiver ìƒíƒœ ì—…ë°ì´íŠ¸
   - íŒ€ì›ë“¤ê³¼ ë¦¬ë·°
   - ìµœì¢… ìŠ¹ì¸ ë° ë³´ê³ ì„œ ìƒì„±

2. Cross-team í˜‘ì—… ì‹œë‚˜ë¦¬ì˜¤
   - Design íŒ€: ì´ˆê¸° ë°ì´í„° ì—…ë¡œë“œ
   - Verification íŒ€: ê²€ì¦ ê²°ê³¼ ì¶”ê°€
   - Physical íŒ€: Layout ì •ë³´ ë³‘í•©
   - Manager: ì „ì²´ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§

3. ê¸´ê¸‰ ìˆ˜ì • ì‹œë‚˜ë¦¬ì˜¤
   - Production ì´ìŠˆ ë°œìƒ
   - ì—¬ëŸ¬ ì—”ì§€ë‹ˆì–´ ë™ì‹œ ë¶„ì„
   - ì‹¤ì‹œê°„ ë°ì´í„° ê³µìœ  ë° ìˆ˜ì •
   - ë¹ ë¥¸ ì˜ì‚¬ê²°ì • ì§€ì›
```

## 5. ìë™í™” í…ŒìŠ¤íŠ¸ ì „ëµ

### 5.1 CI/CD íŒŒì´í”„ë¼ì¸ í†µí•©

```yaml
test_pipeline:
  - unit_tests:
      - test_data_validation
      - test_lock_manager
      - test_file_operations
  
  - integration_tests:
      - test_mode_transitions
      - test_save_operations
      - test_concurrent_access
  
  - e2e_tests:
      - test_user_workflows
      - test_collaboration
  
  - performance_tests:
      - test_load_times
      - test_memory_usage
  
  - regression_tests:
      - test_backward_compatibility
      - test_existing_features
```

### 5.2 í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ëª©í‘œ

- Unit Test: 80% ì´ìƒ
- Integration Test: Core ê¸°ëŠ¥ 100%
- E2E Test: ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤ 100%
- Performance: ëª¨ë“  KPI ë‹¬ì„±

## 6. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„

### 6.1 í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹

```python
test_datasets = {
    "small": "1K rows Ã— 10 cols",      # ë¹ ë¥¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    "medium": "100K rows Ã— 20 cols",   # ì¼ë°˜ í…ŒìŠ¤íŠ¸
    "large": "10M rows Ã— 30 cols",     # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    "xlarge": "100M rows Ã— 50 cols",   # ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
}
```

### 6.2 í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë³„ ë°ì´í„°

- ì •ìƒ ë°ì´í„°: í‘œì¤€ Parquet í˜•ì‹
- ì—£ì§€ ì¼€ì´ìŠ¤: íŠ¹ìˆ˜ ë¬¸ì, NULL ê°’, ê·¹ë‹¨ê°’
- ì†ìƒ ë°ì´í„°: íŒŒì¼ ì†ìƒ ì‹œë®¬ë ˆì´ì…˜
- ë ˆê±°ì‹œ ë°ì´í„°: ì´ì „ ë²„ì „ í˜¸í™˜ì„±

## 7. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê³„íš

### Phase 1: ê°œë°œ ì¤‘ í…ŒìŠ¤íŠ¸ (í˜„ì¬)

- ê°œë°œê³¼ ë™ì‹œì— unit test ì‘ì„±
- ê¸°ëŠ¥ êµ¬í˜„ ì§í›„ integration test
- ë§¤ì¼ ìë™í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### Phase 2: í†µí•© í…ŒìŠ¤íŠ¸ (ê°œë°œ ì™„ë£Œ í›„)

- ì „ì²´ ê¸°ëŠ¥ í†µí•© í…ŒìŠ¤íŠ¸
- ë‹¤ì¤‘ ì‚¬ìš©ì ì‹œë®¬ë ˆì´ì…˜
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### Phase 3: UAT (ë°°í¬ ì „)

- ë² íƒ€ ì‚¬ìš©ì 10-20ëª… ì„ ì •
- 2ì£¼ê°„ ì‹¤ì œ ì—…ë¬´ ì ìš©
- í”¼ë“œë°± ìˆ˜ì§‘ ë° ë°˜ì˜

